{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd3d17-e0f9-4310-9066-b1d075d5f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Scraped csv file from python script\n",
    "PATH = \"scraped_feeds.csv\"\n",
    "\n",
    "df_urls = pd.read_csv(PATH)\n",
    "print(df_urls.head())\n",
    "print(df_urls.columns)\n",
    "\n",
    "urls = df_urls[\"FeedURL\"].dropna().astype(str).unique().tolist()\n",
    "\n",
    "print(\"URLs loaded:\", len(urls))\n",
    "print(\"Sample:\", urls[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30027236-3b35-468c-91ac-134ab27ca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from functools import lru_cache\n",
    "\n",
    "BASE = \"https://public.api.bsky.app/xrpc\"\n",
    "S = requests.Session()\n",
    "S.headers.update({\"User-Agent\": \"feed-research/0.1\"})\n",
    "\n",
    "def parse_feed_url(url: str):\n",
    "    parts = urlparse(url).path.strip(\"/\").split(\"/\")\n",
    "    if len(parts) >= 4 and parts[0] == \"profile\" and parts[2] == \"feed\":\n",
    "        return parts[1], parts[3]\n",
    "    return None, None\n",
    "\n",
    "@lru_cache(maxsize=50000)\n",
    "def resolve_handle_to_did(handle: str) -> str | None:\n",
    "    r = S.get(f\"{BASE}/com.atproto.identity.resolveHandle\", params={\"handle\": handle}, timeout=20)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    return r.json().get(\"did\")\n",
    "\n",
    "def get_feed_generator(at_uri: str) -> dict | None:\n",
    "    r = S.get(f\"{BASE}/app.bsky.feed.getFeedGenerator\", params={\"feed\": at_uri}, timeout=20)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    return r.json().get(\"view\")\n",
    "\n",
    "def url_to_feed_record(url: str):\n",
    "    handle, rkey = parse_feed_url(url)\n",
    "    if not handle or not rkey:\n",
    "        return None\n",
    "\n",
    "    did = resolve_handle_to_did(handle)\n",
    "    if not did:\n",
    "        return None\n",
    "\n",
    "    at_uri = f\"at://{did}/app.bsky.feed.generator/{rkey}\"\n",
    "    view = get_feed_generator(at_uri)\n",
    "    if not view:\n",
    "        return None\n",
    "\n",
    "    creator = view.get(\"creator\") or {}\n",
    "\n",
    "    return {\n",
    "        \"feed_url\": url,\n",
    "        \"feed_at_uri\": view.get(\"uri\") or at_uri,\n",
    "        \"feed_cid\": view.get(\"cid\"),\n",
    "        \"creator_did\": creator.get(\"did\") or did,\n",
    "        \"creator_handle\": creator.get(\"handle\") or handle,\n",
    "        \"creator_display_name\": creator.get(\"displayName\", \"\"),\n",
    "\n",
    "        \"feed_display_name\": view.get(\"displayName\", \"\"),\n",
    "        \"feed_description\": view.get(\"description\", \"\") or \"\",\n",
    "        \"like_count\": int(view.get(\"likeCount\") or 0),\n",
    "        \"indexed_at\": view.get(\"indexedAt\", \"\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca2aab4-2518-42c0-a0ad-62174f6c4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Dedupe\n",
    "records = []\n",
    "errors = []\n",
    "\n",
    "seen_urls = set()\n",
    "for u in urls:\n",
    "    if u in seen_urls:\n",
    "        continue\n",
    "    seen_urls.add(u)\n",
    "\n",
    "    rec = url_to_feed_record(u)\n",
    "    if rec is None:\n",
    "        errors.append({\"feed_url\": u, \"error\": \"lookup_failed\"})\n",
    "    else:\n",
    "        records.append(rec)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df_err = pd.DataFrame(errors)\n",
    "\n",
    "print(\"Fetched:\", len(df))\n",
    "print(\"Errors:\", len(df_err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954b3ec-3c0d-4c2f-b267-bcb6e2e3dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second dedupe on feed_uri id\n",
    "df = df.sort_values(\"like_count\", ascending=False).drop_duplicates(\"feed_at_uri\").reset_index(drop=True)\n",
    "print(\"After dedupe(feed_at_uri):\", len(df))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08adc7-f123-4edf-a742-f903599d8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Political Scroing\n",
    "\n",
    "POLITICAL_PATTERNS = [\n",
    "    r\"\\bpolitic(s|al)?\\b\", r\"\\bgovernment\\b\", r\"\\bpolicy\\b\",\n",
    "    r\"\\belection(s)?\\b\", r\"\\bvote(s|d|ing)?\\b\", r\"\\bcampaign\\b\",\n",
    "    r\"\\bcongress\\b\", r\"\\bsenate\\b\", r\"\\bhouse\\b\", r\"\\bwhite house\\b\",\n",
    "    r\"\\bscotus\\b\", r\"\\bsupreme court\\b\", r\"\\bcapitol\\b\", r\"\\bwashington\\b\",\n",
    "\n",
    "    r\"\\bdemocrat(s|ic)?\\b\", r\"\\brepublican(s)?\\b\", r\"\\bgop\\b\",\n",
    "    r\"\\bmaga\\b\", r\"\\bprogressive(s)?\\b\", r\"\\bliberal(s)?\\b\",\n",
    "    r\"\\bconservative(s)?\\b\", r\"\\bleft(ist|y|ies)?\\b\", r\"\\bright[- ]wing\\b\",\n",
    "\n",
    "    # US anchors\n",
    "    r\"\\busa\\b\", r\"\\bunited states\\b\", r\"\\bamerican\\b\", r\"\\bus\\b\",\n",
    "]\n",
    "\n",
    "NONPOLIT_HINTS = [\n",
    "    r\"\\bart\\b\", r\"\\bmusic\\b\", r\"\\bgaming\\b\", r\"\\banime\\b\", r\"\\bsports\\b\",\n",
    "    r\"\\bfootball\\b\", r\"\\bbasketball\\b\", r\"\\bpoetry\\b\", r\"\\bwriting\\b\",\n",
    "    r\"\\bcooking\\b\", r\"\\bfood\\b\", r\"\\btravel\\b\", r\"\\bphotography\\b\",\n",
    "    r\"\\bscience\\b\", r\"\\bmath\\b\", r\"\\bmovies?\\b\", r\"\\btv\\b\",\n",
    "]\n",
    "\n",
    "pol_re = [re.compile(p, re.I) for p in POLITICAL_PATTERNS]\n",
    "non_re = [re.compile(p, re.I) for p in NONPOLIT_HINTS]\n",
    "\n",
    "def score(text: str, regexes):\n",
    "    return sum(1 for rx in regexes if rx.search(text))\n",
    "\n",
    "def classify(name: str, desc: str, like_count: int):\n",
    "    text = f\"{name}\\n{desc}\".strip()\n",
    "    p = score(text, pol_re)\n",
    "    n = score(text, non_re)\n",
    "\n",
    "    # 1) Strong political markers\n",
    "    if p >= 1:\n",
    "        return \"keep\", p, n\n",
    "\n",
    "    # 2) If it's popular, keep it even if it has subtle language\n",
    "    if like_count >= 25:\n",
    "        return \"keep\", p, n\n",
    "\n",
    "    # 3) Drop only if we have clear non-political hits and no political hits\n",
    "    if p == 0 and n >= 2:\n",
    "        return \"drop\", p, n\n",
    "\n",
    "    return \"review\", p, n\n",
    "\n",
    "labels = [classify(r.feed_display_name, r.feed_description, r.like_count) for r in df.itertuples()]\n",
    "df[\"political_label\"] = [x[0] for x in labels]\n",
    "df[\"political_score\"] = [x[1] for x in labels]\n",
    "df[\"nonpolit_score\"] = [x[2] for x in labels]\n",
    "\n",
    "keep = df[df[\"political_label\"] == \"keep\"].copy()\n",
    "review = df[df[\"political_label\"] == \"review\"].copy()\n",
    "drop = df[df[\"political_label\"] == \"drop\"].copy()\n",
    "\n",
    "print(\"KEEP:\", len(keep))\n",
    "print(\"REVIEW:\", len(review))\n",
    "print(\"DROP:\", len(drop))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
